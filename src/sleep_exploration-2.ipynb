{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('../data/training/a_data.csv')\n",
    "labels = pd.read_csv('../data/training/a_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group datapoints into bins, corresponding to a seconnd of recording time\n",
    "data['TimestampToSec'] = data['Timestamp'].astype(int)\n",
    "grouped = data.groupby('TimestampToSec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Energy(coeffs, k):\n",
    "    return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pywt.data\n",
    "mode = pywt.Modes.smooth\n",
    "\n",
    "def signal_decomp(data):\n",
    "    \"\"\"Decompose and plot a signal S.\n",
    "    S = An + Dn + Dn-1 + ... + D1\n",
    "    \"\"\"\n",
    "    w = pywt.Wavelet('db4')\n",
    "    a = data\n",
    "    ca = []\n",
    "    cd = []\n",
    "    for i in range(5):\n",
    "        (a, d) = pywt.dwt(a, w, mode)\n",
    "        ca.append(a)\n",
    "        cd.append(d)  \n",
    "    return ca, cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.signal    \n",
    "\n",
    "# CONSTRUCT FEATURES\n",
    "\n",
    "# for every label, look up the corresponding data\n",
    "features = []\n",
    "for l in range(len(labels)):\n",
    "    time = labels['Timestamp'][l]\n",
    "    slice = grouped.get_group(time)\n",
    "    # for every channel\n",
    "    power_all_channels = []\n",
    "    # 1-7 EEG, 8th channel is ECG data\n",
    "    for ch in range(8):\n",
    "        single_sec_ch = slice['Ch{}'.format(ch)]\n",
    "        \n",
    "        # median filter the data\n",
    "        pre_processed = scipy.signal.medfilt(single_sec_ch, kernel_size=3)  \n",
    "        \n",
    "        _, cd = signal_decomp(pre_processed)\n",
    "        # for every decomp. level\n",
    "        power = []\n",
    "        for l in range(5):\n",
    "            power.append(Energy(cd, l))\n",
    "            \n",
    "        # collect power for all channels into one vector \n",
    "        power_all_channels.append(power) \n",
    "    # currently mean power of the frequency bands over all channels are the only features\n",
    "    power_vec = np.asarray(power_all_channels).flatten()\n",
    "    features.append(power_vec)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.asarray(features).shape)\n",
    "target_names = np.unique(labels['Event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "## Random Forst\n",
    "clf = ensemble.RandomForestClassifier(n_estimators = 10, criterion='entropy', class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "predicted = cross_val_predict(clf, features, labels['Event'], cv=10)\n",
    "\n",
    "acc = metrics.accuracy_score(labels['Event'], predicted)\n",
    "print(\"This is the Score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize false predictions\n",
    "def vis_clfs(targets, predicted):\n",
    "    # color coding grayscale\n",
    "    color = {'stage_q_N34' : 0, 'stage_q_N23': 50, 'stage_q_N12': 100, 'stage_q_REM1': 150, 'stage_q_Wake0': 200}\n",
    "    label_text = ['N34', 'N23', 'N12', 'REM', 'Wake']\n",
    "    false_pred = np.where(predicted != targets)\n",
    "    timepoints = range(0,len(predicted))\n",
    "\n",
    "    rows = np.ceil((len(predicted) / 500)).astype(int) * 10\n",
    "    cols = 500\n",
    "    image = np.ones((rows,cols), dtype=np.int16) * 255\n",
    "\n",
    "    for timepoint in timepoints:\n",
    "        x = timepoint % 500 \n",
    "        y = int(timepoint / 500) * 10\n",
    "\n",
    "        image[y:y+10,x] = color[predicted[timepoint]]\n",
    "    \n",
    "    import matplotlib.patches as mpatches\n",
    "    plt.figure(frameon=False, figsize=(16,16))  \n",
    "    plt.title('Classification Results', fontsize=18)\n",
    "    plt.axis('off')   \n",
    "    im = plt.imshow(image,cmap=plt.cm.bone, vmin = 0, vmax = 255)\n",
    "    # get the colors of the values, according to the \n",
    "    # colormap used by imshow\n",
    "    values = [0,50,100,150,200]\n",
    "    colors = [im.cmap(im.norm(value)) for value in values]\n",
    "    # create a patch (proxy artist) for every color \n",
    "    patches = [ mpatches.Patch(color=colors[i], label=\"{l}\".format(l=label_text[i]) ) for i in range(len(values)) ]\n",
    "    # put those patched as legend-handles into the legend\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=18 )\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vis_clfs(labels['Event'], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smooth(a, n=3) :\n",
    "    res = np.zeros((5,a.shape[1]-n))\n",
    "    # sum over the last n timepoints\n",
    "    for timep in range(a.shape[1]-n):\n",
    "        if(timep >= n):\n",
    "            acc_sum = np.sum(a[:,timep-n:timep], axis = 1) \n",
    "            res[:,timep] = acc_sum\n",
    "     \n",
    "    # assign class according to the most ofen occuring class within last 5 predictions\n",
    "    classes = np.argmax(res,axis=0)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert predictions into a one hot vector\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(predicted)\n",
    "print(lb.classes_)\n",
    "onehot_pred = lb.transform(predicted)\n",
    "#onehot_pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_length = 15\n",
    "\n",
    "mov_pred = smooth(onehot_pred.T, n = filter_length)\n",
    "t = labels['Event'].as_matrix()[filter_length:]\n",
    "print(mov_pred.shape)\n",
    "p = lb.classes_[mov_pred]\n",
    "vis_clfs(t, p)\n",
    "\n",
    "acc = metrics.accuracy_score(t, p)\n",
    "print(\"This is the Score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        float_formatter = lambda x: \"%.2f\" % x\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "class_names, counts = np.unique(labels['Event'], return_counts=True)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(labels['Event'], predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
