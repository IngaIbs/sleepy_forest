{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for the sleep data project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "The purpose of this project is to use ensemble methods to discriminate between different sleep stages from EEG sleep data. We experiment with different ensemble methods and parameters in order to compare the results and find the most appropriate approach given our data.\n",
    "\n",
    "We first prepare and filter the data for further use. Then perform Wavelet decomposition to identify and extract different frequencies from the data. Subsequently, we do feature extraction, where features correspond to the power of the frequency bands. Afterwards, we train and test two different ensemble methods; Random Forest and Adaboost. In order to optimize these results we then perform hyperparameter search and compare the results. To finish we propose and implement further methods to optimize classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep Data Description\n",
    "\n",
    "Data was collected with the Traumschreiber, high-tech sleep mask developed for research purposes.\n",
    "\n",
    "The data used to train and test the classifier consists of five data sets corresponding to different nights of sleep. Each data set containing information from seven Electroencephalogram (EEG) channels and one Electrocardiogram (ECG) channel, recorded for about seven hours of sleep.\n",
    "\n",
    "Data is labeled by epochs of one second, where each second contains about 200 microvolt points. These labels correspond to the sleep stages introduced by the American Academy of Sleep Medicine (AASM) that differentiates between five main sleeping stages: \n",
    "\n",
    "(1) Wakefulness: Active wakefulness with beta waves (+13 Hz) and relaxed wakefulness with mostly alpha wave (8-13 Hz).\n",
    "(2) Non-Rapid Eye Movement (NREM) 1: Dominated by Theta activity (4-7 Hz).\n",
    "(3) NREM-2: Characterized by Theta waves, sleep spindles and K-complexes.\n",
    "(4) NREM-3: Dominated by Delta wave (0.5-2 Hz) along with some sleep spindles.\n",
    "(5) Rapid Eye Movement (REM): Characterized by low-amplitude mixed-frequency brain waves. Theta, alpha and even beta activity can be observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage    \n",
    "import scipy.signal    \n",
    "import os\n",
    "import pickle\n",
    "from feature_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data for subject a\n",
    "data = pd.read_csv('../src/a_data.csv')\n",
    "labels = pd.read_csv('../src/a_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median filter justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data presented huge peaks that where probably product of interference in the Bluetooth signal. To eliminate peaks while altering the data as little as possible, we decided to implement a median filter by using the Scikit median filter function, with a Kernel size of three. This filter runs through the signal entry by entry, replacing each entry with the median of neighboring entries. The pattern of neighbors is referred as the Kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example Plot from data set 1, EEG channel 0\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(data['Ch0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(data['Ch0'][1034300:1034500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median filter implementation loop\n",
    "pre_processed = scipy.signal.medfilt(data['Ch0'], kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(pre_processed[1034300:1034500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group datapoints into bins, corresponding to a second of recording time maybe mit preprocessing\n",
    "data['TimestampToSec'] = data['Timestamp'].astype(int)\n",
    "grouped = data.groupby('TimestampToSec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a second of data of all channels\n",
    "\n",
    "single_sec_data = grouped.get_group(1489016350)\n",
    "single_sec_ch = single_sec_data['Ch0']\n",
    "\n",
    "#plt.plot(single_sec_ch)\n",
    "plt.plot(single_sec_data['Ch0'])\n",
    "plt.plot(single_sec_data['Ch1'])\n",
    "plt.plot(single_sec_data['Ch2'])\n",
    "plt.plot(single_sec_data['Ch3'])\n",
    "plt.plot(single_sec_data['Ch4'])\n",
    "plt.plot(single_sec_data['Ch5'])\n",
    "plt.plot(single_sec_data['Ch6'])\n",
    "plt.plot(single_sec_data['Ch7'])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Wavelet Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Wavelet Transform Overview\n",
    "The wavelet are waves of irregular form in shape and compactly supported. These properties along with the main two operations of scaling and shifting, which produce a time-scale representation of the signal, make wavelets an ideal tool for analysing signals of non-stationary nature. Their irregular shape makes them suitable for analysing signals with discontinuities, and their compactly supported nature enables temporal localisation. Motivated by the adaptive time-frequency resolution properties of the Wavelet Transform and the corresponding fact that some stages in sleep recordings have a well defined time-frequency domain we opted to use Discrete Wavelet Decomposition to obtain five sub-bands of the original signal and consequently performed feature extraction on them for the classification.\n",
    "\n",
    "The Discrete Wavelet Decomposition algorithm we implemented relays firstly on a dyadic scaling of the wavelength and secondly on a discrete shifting across the original signal. The first operation serves as half band filter which halves the highest frequency component of the original signal,providing  lower computational time and less memory usage. This in accordance to Nyquistâ€™s sampling rate allowing the usage of half of the previous sample points at each level of the decomposition for a proper reconstruction of the original signal. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"wavelet transform EEG ERD ERS event-related potentials time frequencya.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction for sleep classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = pywt.Modes.smooth\n",
    "\n",
    "def signal_decomp(data):\n",
    "    \"\"\"Decompose and plot a signal S.\n",
    "    S = An + Dn + Dn-1 + ... + D1\n",
    "    \"\"\"\n",
    "    w = pywt.Wavelet('db4')\n",
    "    a = data\n",
    "    ca = []\n",
    "    cd = []\n",
    "    for i in range(5):\n",
    "        (a, d) = pywt.dwt(a, w, mode)\n",
    "        ca.append(a)\n",
    "        cd.append(d)  \n",
    "    return ca, cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Energy(coeffs, k):\n",
    "    return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Decomposition\n",
    "The algorithm adopted can be better visualized as a tree of low and high pass filter, which perform the decomposition of the signal into different frequency bands applying successive filtering of the time domain signal. \n",
    "The original signal is successively decomposed into components of lower resolution, while the high frequency components are not analysed any further.This decomposition halves the time resolution since only half the number of samples now characterizes the entire signal. \n",
    "However it doubles the frequency resolution, since the frequency band of the signal now spans only half the previous.The maximum depth of decomposition is dependent on the input size of the data to be analysed, with 2N data samples enabling the breakdown of the signal into N discrete levels using the discrete wavelet transform. This procedure thus offers a good time resolution at high frequencies, and good frequency resolution at low frequencies. \n",
    "\n",
    "This matches well the resolution of each sub-band with certain sleep stages patterns, for example capturing at an higher time resolution the signal of the beta stage, which shows abrupt discontinuities .\n",
    "We discarded the first two levels of the decomposition simply because those frequency bands are completely absent it the original signal. In conclusion the frequencies that are most prominent in the original signal will appear as high amplitudes in the corresponding region of the Discrete Wavelet Transform signal that includes those particular frequencies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Untitled Diagram (3).png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_signal_decomp(data, w, title):\n",
    "    ca, cd = signal_decomp(data)\n",
    "        \n",
    "    rec_a = []\n",
    "    rec_d = []\n",
    "\n",
    "    for i, coeff in enumerate(ca):\n",
    "        coeff_list = [coeff, None] + [None] * i\n",
    "        rec_a.append(pywt.waverec(coeff_list, w))\n",
    "\n",
    "    for i, coeff in enumerate(cd):\n",
    "        coeff_list = [None, coeff] + [None] * i\n",
    "        rec_d.append(pywt.waverec(coeff_list, w))\n",
    "\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax_main = fig.add_subplot(len(rec_a) + 1, 1, 1)\n",
    "    ax_main.set_title(title, fontsize=20)\n",
    "    ax_main.plot(data)\n",
    "    ax_main.set_xlim(data.index[0], data.index[len(data) - 1])\n",
    "\n",
    "    for i, y in enumerate(rec_a):\n",
    "        ax = fig.add_subplot(len(rec_a) + 1, 2, 3 + i * 2)\n",
    "        ax.plot(y, 'r')\n",
    "        ax.set_xlim(0, len(y) - 1)\n",
    "        ax.set_ylabel(\"A%d\" % (i + 1))\n",
    "\n",
    "    for i, y in enumerate(rec_d):\n",
    "        ax = fig.add_subplot(len(rec_d) + 1, 2, 4 + i * 2)\n",
    "        ax.plot(y, 'g')\n",
    "        ax.set_xlim(0, len(y) - 1)\n",
    "        ax.set_ylabel(\"D%d\" % (i + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_signal_decomp(single_sec_ch, 'db4', \"Single Sec single Channel EEG data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ignore from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT FEATURES\n",
    "\n",
    "# for every label, look up the corresponding data\n",
    "features = []\n",
    "for l in range(len(labels)):\n",
    "    try:\n",
    "        time = labels['Timestamp'][l]\n",
    "        slice = grouped.get_group(time)\n",
    "    except KeyError:\n",
    "        print(time)\n",
    "        pass\n",
    "    # for every channel\n",
    "    power_all_channels = []\n",
    "    # 1-7 EEG, 8th channel is ECG data\n",
    "    for ch in range(8):\n",
    "        single_sec_ch = slice['Ch{}'.format(ch)]\n",
    "        \n",
    "        # median filter the data\n",
    "        pre_processed = scipy.signal.medfilt(single_sec_ch, kernel_size=3)  \n",
    "        \n",
    "        _, cd = signal_decomp(pre_processed)\n",
    "        # for every decomp. level\n",
    "        power = []\n",
    "        for l in range(5):\n",
    "            power.append(Energy(cd, l))\n",
    "            \n",
    "        # collect power for all channels into one vector \n",
    "        power_all_channels.append(power) \n",
    "    # currently mean power of the frequency bands over all channels are the only features\n",
    "    power_vec = np.asarray(power_all_channels).flatten()\n",
    "    features.append(power_vec)\n",
    "features =np.asarray(features)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing Bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
